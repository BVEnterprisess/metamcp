# Streamable HTTP API

HTTP API endpoints that support streaming responses for real-time data processing.

## Overview

MetaMCP provides streamable HTTP endpoints for scenarios requiring:

- Real-time tool execution with streaming results
- Large data transfers with progress updates
- Long-running operations with intermediate feedback
- Chunked responses for better user experience

## Streaming Endpoints

### Stream Tool Execution

Execute tools with streaming response for real-time feedback.

```http
POST /api/namespaces/{namespaceId}/tools/execute/stream
```

**Headers:**
```http
Content-Type: application/json
Accept: application/x-ndjson
Authorization: Bearer your-api-key
```

**Request Body:**
```json
{
  "name": "string",
  "arguments": {
    "key": "value"
  },
  "stream": true
}
```

**Response Format:**

The response is streamed as newline-delimited JSON (NDJSON):

```bash
curl -X POST \
  -H "Authorization: Bearer mcp_your-api-key" \
  -H "Content-Type: application/json" \
  -H "Accept: application/x-ndjson" \
  -d '{
    "name": "process_large_file",
    "arguments": {
      "path": "/large-dataset.csv"
    }
  }' \
  https://your-domain.com/api/namespaces/namespace-uuid/tools/execute/stream
```

**Example Response Stream:**

```json
{"type": "start", "executionId": "exec-123", "timestamp": "2024-01-15T12:45:00Z"}
{"type": "progress", "completed": 10, "total": 100, "message": "Processing row 10"}
{"type": "progress", "completed": 25, "total": 100, "message": "Processing row 25"}
{"type": "progress", "completed": 50, "total": 100, "message": "Processing row 50"}
{"type": "result", "data": {"processed": 75, "errors": 0}}
{"type": "progress", "completed": 100, "total": 100, "message": "Complete"}
{"type": "end", "executionTime": 5000, "status": "success"}
```

### Stream Logs

Stream execution logs in real-time.

```http
GET /api/logs/stream
```

**Parameters:**

| Parameter | Type | Description |
|-----------|------|-------------|
| `namespace` | string | Filter by namespace ID |
| `tool` | string | Filter by tool name |
| `level` | string | Filter by log level: `info`, `warn`, `error` |
| `follow` | boolean | Continue streaming new logs (default: true) |

**Example Request:**

```bash
curl -N \
  -H "Authorization: Bearer mcp_your-api-key" \
  -H "Accept: application/x-ndjson" \
  "https://your-domain.com/api/logs/stream?namespace=namespace-uuid&follow=true"
```

**Example Response Stream:**

```json
{"timestamp": "2024-01-15T12:45:00Z", "level": "info", "toolName": "read_file", "message": "File read started"}
{"timestamp": "2024-01-15T12:45:01Z", "level": "info", "toolName": "read_file", "message": "File read completed"}
{"timestamp": "2024-01-15T12:45:02Z", "level": "error", "toolName": "write_file", "message": "Permission denied"}
```

### Stream Metrics

Stream system and performance metrics.

```http
GET /api/metrics/stream
```

**Parameters:**

| Parameter | Type | Description |
|-----------|------|-------------|
| `interval` | integer | Update interval in seconds (default: 5, min: 1, max: 60) |
| `metrics` | string | Comma-separated list of metrics to include |

**Available Metrics:**
- `cpu` - CPU usage percentage
- `memory` - Memory usage percentage  
- `requests` - Requests per second
- `errors` - Error rate
- `latency` - Average response time
- `connections` - Active connections

**Example Request:**

```bash
curl -N \
  -H "Authorization: Bearer mcp_your-api-key" \
  -H "Accept: application/x-ndjson" \
  "https://your-domain.com/api/metrics/stream?interval=10&metrics=cpu,memory,requests"
```

**Example Response Stream:**

```json
{"timestamp": "2024-01-15T12:45:00Z", "cpu": 25.3, "memory": 67.8, "requests": 120}
{"timestamp": "2024-01-15T12:45:10Z", "cpu": 28.1, "memory": 68.2, "requests": 115}
{"timestamp": "2024-01-15T12:45:20Z", "cpu": 22.9, "memory": 66.9, "requests": 125}
```

## Message Types

### Tool Execution Stream Messages

#### start
Indicates tool execution has begun.

```json
{
  "type": "start",
  "executionId": "exec-123",
  "toolName": "process_data",
  "timestamp": "2024-01-15T12:45:00Z",
  "estimatedDuration": 30000
}
```

#### progress
Progress updates during execution.

```json
{
  "type": "progress",
  "executionId": "exec-123",
  "completed": 50,
  "total": 100,
  "percentage": 50.0,
  "message": "Processing item 50 of 100",
  "timestamp": "2024-01-15T12:45:15Z"
}
```

#### result
Intermediate or partial results.

```json
{
  "type": "result",
  "executionId": "exec-123",
  "data": {
    "processedItems": 25,
    "currentBatch": ["item1", "item2", "item3"]
  },
  "timestamp": "2024-01-15T12:45:10Z"
}
```

#### log
Log messages during execution.

```json
{
  "type": "log",
  "executionId": "exec-123",
  "level": "info",
  "message": "Processing batch 3 of 10",
  "timestamp": "2024-01-15T12:45:12Z"
}
```

#### error
Error messages during execution.

```json
{
  "type": "error",
  "executionId": "exec-123",
  "error": {
    "code": "PROCESSING_ERROR",
    "message": "Failed to process item at index 45",
    "details": {
      "item": "corrupted-data.json",
      "line": 45
    }
  },
  "timestamp": "2024-01-15T12:45:18Z"
}
```

#### end
Indicates execution completion.

```json
{
  "type": "end",
  "executionId": "exec-123",
  "status": "success",
  "finalResult": {
    "totalProcessed": 100,
    "errors": 2,
    "warnings": 5
  },
  "executionTime": 30000,
  "timestamp": "2024-01-15T12:45:30Z"
}
```

## Client Implementation Examples

### JavaScript/Node.js

```javascript
class StreamableClient {
  constructor(apiKey, baseUrl) {
    this.apiKey = apiKey;
    this.baseUrl = baseUrl;
  }

  async executeToolStream(namespaceId, toolName, arguments) {
    const response = await fetch(`${this.baseUrl}/api/namespaces/${namespaceId}/tools/execute/stream`, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${this.apiKey}`,
        'Content-Type': 'application/json',
        'Accept': 'application/x-ndjson'
      },
      body: JSON.stringify({
        name: toolName,
        arguments: arguments
      })
    });

    if (!response.ok) {
      throw new Error(`HTTP ${response.status}: ${response.statusText}`);
    }

    return this.processNDJSONStream(response);
  }

  async processNDJSONStream(response) {
    const reader = response.body.getReader();
    const decoder = new TextDecoder();
    let buffer = '';

    const results = [];

    try {
      while (true) {
        const { done, value } = await reader.read();
        
        if (done) break;

        buffer += decoder.decode(value, { stream: true });
        
        // Process complete lines
        const lines = buffer.split('\n');
        buffer = lines.pop(); // Keep incomplete line in buffer

        for (const line of lines) {
          if (line.trim()) {
            try {
              const message = JSON.parse(line);
              results.push(message);
              this.handleMessage(message);
            } catch (error) {
              console.error('Failed to parse message:', line, error);
            }
          }
        }
      }
    } finally {
      reader.releaseLock();
    }

    return results;
  }

  handleMessage(message) {
    switch (message.type) {
      case 'start':
        console.log(`Execution started: ${message.executionId}`);
        break;
      case 'progress':
        console.log(`Progress: ${message.percentage}% - ${message.message}`);
        break;
      case 'result':
        console.log('Partial result:', message.data);
        break;
      case 'log':
        console.log(`[${message.level}] ${message.message}`);
        break;
      case 'error':
        console.error('Execution error:', message.error);
        break;
      case 'end':
        console.log(`Execution completed: ${message.status}`);
        console.log('Final result:', message.finalResult);
        break;
    }
  }

  async streamLogs(options = {}) {
    const params = new URLSearchParams(options);
    const response = await fetch(`${this.baseUrl}/api/logs/stream?${params}`, {
      headers: {
        'Authorization': `Bearer ${this.apiKey}`,
        'Accept': 'application/x-ndjson'
      }
    });

    return this.processNDJSONStream(response);
  }

  async streamMetrics(options = {}) {
    const params = new URLSearchParams({
      interval: 5,
      ...options
    });
    
    const response = await fetch(`${this.baseUrl}/api/metrics/stream?${params}`, {
      headers: {
        'Authorization': `Bearer ${this.apiKey}`,
        'Accept': 'application/x-ndjson'
      }
    });

    return this.processNDJSONStream(response);
  }
}

// Usage
const client = new StreamableClient('mcp_your-api-key', 'https://your-domain.com');

// Execute tool with streaming
client.executeToolStream('namespace-uuid', 'process_large_file', {
  path: '/data/large-file.csv'
}).then(results => {
  console.log('Execution completed with', results.length, 'messages');
}).catch(error => {
  console.error('Stream execution failed:', error);
});

// Stream logs
client.streamLogs({
  namespace: 'namespace-uuid',
  level: 'error'
});

// Stream metrics
client.streamMetrics({
  interval: 10,
  metrics: 'cpu,memory'
});
```

### Python

```python
import json
import requests
from typing import Iterator, Dict, Any

class StreamableClient:
    def __init__(self, api_key: str, base_url: str):
        self.api_key = api_key
        self.base_url = base_url
        self.headers = {
            'Authorization': f'Bearer {api_key}',
            'Accept': 'application/x-ndjson'
        }

    def execute_tool_stream(self, namespace_id: str, tool_name: str, arguments: Dict[str, Any]) -> Iterator[Dict[str, Any]]:
        """Execute a tool with streaming response."""
        response = requests.post(
            f'{self.base_url}/api/namespaces/{namespace_id}/tools/execute/stream',
            headers={
                **self.headers,
                'Content-Type': 'application/json'
            },
            json={
                'name': tool_name,
                'arguments': arguments
            },
            stream=True
        )
        
        response.raise_for_status()
        
        return self._process_ndjson_stream(response)

    def stream_logs(self, **params) -> Iterator[Dict[str, Any]]:
        """Stream execution logs."""
        response = requests.get(
            f'{self.base_url}/api/logs/stream',
            headers=self.headers,
            params=params,
            stream=True
        )
        
        response.raise_for_status()
        
        return self._process_ndjson_stream(response)

    def stream_metrics(self, **params) -> Iterator[Dict[str, Any]]:
        """Stream system metrics."""
        response = requests.get(
            f'{self.base_url}/api/metrics/stream',
            headers=self.headers,
            params=params,
            stream=True
        )
        
        response.raise_for_status()
        
        return self._process_ndjson_stream(response)

    def _process_ndjson_stream(self, response) -> Iterator[Dict[str, Any]]:
        """Process NDJSON stream from response."""
        for line in response.iter_lines(decode_unicode=True):
            if line:
                try:
                    message = json.loads(line)
                    self._handle_message(message)
                    yield message
                except json.JSONDecodeError as e:
                    print(f"Failed to parse message: {line}, error: {e}")

    def _handle_message(self, message: Dict[str, Any]):
        """Handle incoming stream message."""
        msg_type = message.get('type')
        
        if msg_type == 'start':
            print(f"Execution started: {message.get('executionId')}")
        elif msg_type == 'progress':
            print(f"Progress: {message.get('percentage', 0)}% - {message.get('message', '')}")
        elif msg_type == 'result':
            print(f"Partial result: {message.get('data')}")
        elif msg_type == 'log':
            print(f"[{message.get('level')}] {message.get('message')}")
        elif msg_type == 'error':
            print(f"Execution error: {message.get('error')}")
        elif msg_type == 'end':
            print(f"Execution completed: {message.get('status')}")
            print(f"Final result: {message.get('finalResult')}")

# Usage
client = StreamableClient('mcp_your-api-key', 'https://your-domain.com')

# Execute tool with streaming
for message in client.execute_tool_stream('namespace-uuid', 'process_data', {'input': 'data.csv'}):
    # Messages are automatically handled by _handle_message
    pass

# Stream logs
for log_entry in client.stream_logs(namespace='namespace-uuid', level='error'):
    # Process log entries
    pass

# Stream metrics  
for metrics in client.stream_metrics(interval=10, metrics='cpu,memory'):
    print(f"CPU: {metrics.get('cpu')}%, Memory: {metrics.get('memory')}%")
```

### React Hook

```javascript
import { useState, useEffect, useRef } from 'react';

function useStreamableExecution(apiKey) {
  const [messages, setMessages] = useState([]);
  const [isStreaming, setIsStreaming] = useState(false);
  const [error, setError] = useState(null);
  const abortControllerRef = useRef(null);

  const executeToolStream = async (namespaceId, toolName, arguments) => {
    setMessages([]);
    setIsStreaming(true);
    setError(null);

    abortControllerRef.current = new AbortController();

    try {
      const response = await fetch(`/api/namespaces/${namespaceId}/tools/execute/stream`, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${apiKey}`,
          'Content-Type': 'application/json',
          'Accept': 'application/x-ndjson'
        },
        body: JSON.stringify({
          name: toolName,
          arguments: arguments
        }),
        signal: abortControllerRef.current.signal
      });

      if (!response.ok) {
        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
      }

      const reader = response.body.getReader();
      const decoder = new TextDecoder();
      let buffer = '';

      while (true) {
        const { done, value } = await reader.read();
        
        if (done) break;

        buffer += decoder.decode(value, { stream: true });
        
        const lines = buffer.split('\n');
        buffer = lines.pop();

        for (const line of lines) {
          if (line.trim()) {
            try {
              const message = JSON.parse(line);
              setMessages(prev => [...prev, message]);
              
              if (message.type === 'end') {
                setIsStreaming(false);
              }
            } catch (err) {
              console.error('Failed to parse message:', line, err);
            }
          }
        }
      }
    } catch (err) {
      if (err.name !== 'AbortError') {
        setError(err);
      }
    } finally {
      setIsStreaming(false);
    }
  };

  const cancelExecution = () => {
    if (abortControllerRef.current) {
      abortControllerRef.current.abort();
    }
  };

  useEffect(() => {
    return () => {
      if (abortControllerRef.current) {
        abortControllerRef.current.abort();
      }
    };
  }, []);

  return {
    messages,
    isStreaming,
    error,
    executeToolStream,
    cancelExecution
  };
}

// Usage in component
function StreamingToolExecution() {
  const { messages, isStreaming, error, executeToolStream, cancelExecution } = 
    useStreamableExecution('mcp_your-api-key');

  const handleExecute = () => {
    executeToolStream('namespace-uuid', 'process_data', {
      input: 'large-dataset.csv'
    });
  };

  const getProgress = () => {
    const progressMessages = messages.filter(m => m.type === 'progress');
    return progressMessages.length > 0 ? progressMessages[progressMessages.length - 1] : null;
  };

  const progress = getProgress();

  return (
    <div>
      <button onClick={handleExecute} disabled={isStreaming}>
        {isStreaming ? 'Executing...' : 'Execute Tool'}
      </button>
      
      {isStreaming && (
        <button onClick={cancelExecution}>
          Cancel
        </button>
      )}

      {progress && (
        <div>
          <div>Progress: {progress.percentage}%</div>
          <div>{progress.message}</div>
          <progress value={progress.completed} max={progress.total} />
        </div>
      )}

      {error && (
        <div style={{ color: 'red' }}>
          Error: {error.message}
        </div>
      )}

      <div>
        <h3>Messages ({messages.length})</h3>
        <div style={{ maxHeight: '300px', overflow: 'auto' }}>
          {messages.map((message, index) => (
            <div key={index} style={{ marginBottom: '8px', fontSize: '12px' }}>
              <strong>{message.type}</strong>: {JSON.stringify(message, null, 2)}
            </div>
          ))}
        </div>
      </div>
    </div>
  );
}
```

## Error Handling

### Connection Errors

Handle network and connection issues:

```javascript
async function executeWithRetry(client, maxRetries = 3) {
  for (let attempt = 1; attempt <= maxRetries; attempt++) {
    try {
      return await client.executeToolStream('namespace-uuid', 'tool_name', {});
    } catch (error) {
      if (attempt === maxRetries) {
        throw error;
      }
      
      const delay = Math.pow(2, attempt) * 1000;
      console.log(`Attempt ${attempt} failed, retrying in ${delay}ms...`);
      await new Promise(resolve => setTimeout(resolve, delay));
    }
  }
}
```

### Stream Interruption

Handle stream interruptions gracefully:

```javascript
function processStreamWithTimeout(stream, timeoutMs = 30000) {
  return Promise.race([
    stream,
    new Promise((_, reject) => 
      setTimeout(() => reject(new Error('Stream timeout')), timeoutMs)
    )
  ]);
}
```

## Performance Considerations

### Buffering

Implement client-side buffering for high-frequency streams:

```javascript
class BufferedStream {
  constructor(batchSize = 10, flushInterval = 1000) {
    this.batchSize = batchSize;
    this.flushInterval = flushInterval;
    this.buffer = [];
    this.timer = null;
  }

  push(message) {
    this.buffer.push(message);
    
    if (this.buffer.length >= this.batchSize) {
      this.flush();
    } else if (!this.timer) {
      this.timer = setTimeout(() => this.flush(), this.flushInterval);
    }
  }

  flush() {
    if (this.buffer.length > 0) {
      this.processBatch(this.buffer.splice(0));
    }
    
    if (this.timer) {
      clearTimeout(this.timer);
      this.timer = null;
    }
  }

  processBatch(messages) {
    // Process batch of messages
    console.log(`Processing batch of ${messages.length} messages`);
  }
}
```

### Memory Management

Limit message history to prevent memory leaks:

```javascript
class StreamProcessor {
  constructor(maxMessages = 1000) {
    this.maxMessages = maxMessages;
    this.messages = [];
  }

  addMessage(message) {
    this.messages.push(message);
    
    if (this.messages.length > this.maxMessages) {
      this.messages.shift(); // Remove oldest message
    }
  }
}
```

## Security

### Rate Limiting

Streaming endpoints have specific rate limits:
- Maximum 5 concurrent streams per API key
- Stream duration limited to 1 hour
- Message rate limited to 100 messages/second

### Authentication

All streaming endpoints require valid authentication and respect the same permission model as regular API endpoints.

### Data Validation

Stream messages are validated on both client and server sides to ensure data integrity and prevent injection attacks. 